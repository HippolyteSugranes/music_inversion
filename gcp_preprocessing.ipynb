{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Cloud Plateform\n",
    "- Use of GCP bucket files to store wav files.\n",
    "- Convert wav to npy file which avoid the loss of information in comparison to jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import tarfile\n",
    "import pathlib\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "\n",
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # source_blob_name = \"storage-object-name\"\n",
    "    # destination_file_name = \"local/path/to/file\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "\n",
    "    print(\n",
    "        \"Blob {} downloaded to {}.\".format(\n",
    "            source_blob_name, destination_file_name\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob IRMAS-TestingData-Part1.tar downloaded to IRMA_test_1.tar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:12<04:49, 72.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob wav_instruments.tar downloaded to instruments.tar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [02:55<04:04, 81.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob dataset_composer.tar downloaded to composers.tar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [04:39<02:56, 88.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob IRMAS-TestingData-Part2.tar downloaded to IRMA_test_2.tar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [06:16<01:30, 90.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob IRMAS-TestingData-Part3.tar downloaded to IRMA_test_3.tar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [07:07<00:00, 85.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 52s, sys: 55.4 s, total: 2min 47s\n",
      "Wall time: 7min 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#Import files from bucket\n",
    "bucket_name = 'music_file'\n",
    "files_to_import = {'wav_instruments.tar':'instruments.tar',\n",
    "                   'dataset_composer.tar':'composers.tar',\n",
    "                  'IRMAS-TestingData-Part1.tar':'IRMA_test_1.tar',\n",
    "                  'IRMAS-TestingData-Part2.tar':'IRMA_test_2.tar',\n",
    "                  'IRMAS-TestingData-Part3.tar':'IRMA_test_3.tar'}\n",
    "\n",
    "for source_blob_name, destination_file_name in tqdm(files_to_import.items()):\n",
    "    download_blob(bucket_name, source_blob_name, destination_file_name)\n",
    "    file = tarfile.open(destination_file_name, mode=\"r\")\n",
    "    file.extractall(path = destination_file_name[:-4])\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy files creation\n",
    "def files_processing(filepath):\n",
    "    file_lenght = 20 #second\n",
    "    sampling_rate = 44100\n",
    "    n_fft = 4096\n",
    "    hop_length = int(n_fft/4)\n",
    "    channels = 1 # 2 for stereo\n",
    "    audio_binary = tf.io.read_file(filepath)\n",
    "    waveform = tf.audio.decode_wav(audio_binary,\n",
    "                                 desired_channels = channels)\n",
    "\n",
    "    signal = tf.reshape(waveform.audio,[channels,-1])\n",
    "    print(signal.shape)\n",
    "    stft = tf.signal.stft(signal,\n",
    "                        frame_length=n_fft,\n",
    "                        frame_step = hop_length)\n",
    "    stft_amp = tf.abs(stft)\n",
    "    stft_amp = tf.transpose(stft_amp,perm=[2,1,0])\n",
    "    return stft_amp\n",
    "\n",
    "def full_pre_processing(folder):\n",
    "    train_folder = pathlib.Path(folder + 'wav')\n",
    "    files_path = [str(sound_path) for sound_path in list(train_folder.glob(\"*/*\"))]\n",
    "    data_spec = tf.data.Dataset.from_tensor_slices(files_path)\n",
    "    data_spec = data_spec.map(files_processing)\n",
    "    return files_path,data_spec\n",
    "\n",
    "def folder_formating(folder):\n",
    "    directory_wav = folder + 'wav'\n",
    "    directory_npy = folder + 'npy'\n",
    "\n",
    "    if 'npy' not in os.listdir(directory_wav[:-4]):\n",
    "        os.mkdir(directory_npy)\n",
    "\n",
    "    for sub_folder in os.listdir(directory_wav):\n",
    "        if sub_folder not in os.listdir(directory_npy):\n",
    "            os.mkdir(directory_npy + '/' + sub_folder)\n",
    "    \n",
    "    return directory_wav,directory_npy\n",
    "\n",
    "def folder_formating_cqt(folder):\n",
    "    directory_wav = folder + 'wav'\n",
    "    directory_cqt = folder + 'cqt'\n",
    "\n",
    "    if 'cqt' not in os.listdir(directory_wav[:-4]):\n",
    "        os.mkdir(directory_cqt)\n",
    "\n",
    "    for sub_folder in os.listdir(directory_wav):\n",
    "        if sub_folder not in os.listdir(directory_cqt):\n",
    "            os.mkdir(directory_cqt + '/' + sub_folder)\n",
    "    \n",
    "    return directory_wav,directory_cqt\n",
    "\n",
    "def cqt_transform(path):\n",
    "    waveform = librosa.load(path,sr = 44100)[0]\n",
    "    cqt = librosa.core.cqt(waveform,hop_length = 256, n_bins=252, bins_per_octave=3*12)\n",
    "    cqt = librosa.util.normalize(cqt, norm=1)\n",
    "    cqt_amp = np.abs(cqt)\n",
    "    cqt_amp = np.reshape(cqt_amp,(cqt_amp.shape[0],cqt_amp.shape[1],1))\n",
    "    return cqt_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, None)\n",
      "1106\n",
      "1106\r"
     ]
    }
   ],
   "source": [
    "# Transformation des fichier .wav en numpy pour accélerer l'entrainement du réseau de neurone\n",
    "folders = ['composers/dataset/']#,'dataset_composer/dataset/']\n",
    "for folder in folders:\n",
    "    n = 0\n",
    "    directory_wav,directory_npy = folder_formating(folder)\n",
    "    files_path,data_spec = full_pre_processing(folder)\n",
    "    print(len(files_path))\n",
    "    \n",
    "    for file in data_spec:\n",
    "        filename = files_path[n].replace('wav','npy')\n",
    "        np.save(filename,file.numpy())\n",
    "        n+=1\n",
    "        print(n,end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6705\n",
      "1106\n",
      "1105\r"
     ]
    }
   ],
   "source": [
    "folders = ['instruments/','composers/dataset/']\n",
    "for folder in folders:\n",
    "    \n",
    "    directory_wav,directory_cqt = folder_formating_cqt(folder)\n",
    "    train_folder = pathlib.Path(folder + 'wav')\n",
    "    \n",
    "    files_path = [str(sound_path) for sound_path in list(train_folder.glob(\"*/*\"))]\n",
    "    n=0\n",
    "    print(len(files_path))\n",
    "    for path in files_path:\n",
    "        cqt = cqt_transform(path)\n",
    "        filename = path.replace('.wav','.npy').replace('wav/','cqt/')\n",
    "        np.save(filename,cqt)\n",
    "        print(n,end = '\\r')\n",
    "        n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.127531"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('instruments/cqt/pia/[pia][cla]1284__1.npy').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction de formatage des fichiers de test du réseau\n",
    "\n",
    "def test_formating(path):\n",
    "\n",
    "    n_fft = 4096\n",
    "    hop_length = int(n_fft/4)\n",
    "    channels = 1 # 2 for stereo\n",
    "\n",
    "    filepath = test_path[0]\n",
    "    audio_binary = tf.io.read_file(filepath)\n",
    "    waveform = tf.audio.decode_wav(audio_binary,\n",
    "                                    desired_channels = 1)\n",
    "\n",
    "    file = next(iter(waveform))\n",
    "    out = []\n",
    "    lenght = 132299\n",
    "    for i in range(0,min(int(len(file)/lenght),16)):\n",
    "        start = i*lenght\n",
    "        end = (i+1)*lenght\n",
    "        out.append(file[start:end,:])\n",
    "\n",
    "    empty_file = tf.constant([[0.0] for i in range(0,lenght)])\n",
    "    save = len(out)\n",
    "    while len(out) < 16:\n",
    "        out.append(empty_file)\n",
    "\n",
    "    out_stft = []\n",
    "    for extract in out:\n",
    "        signal = tf.reshape(extract,[channels,-1])\n",
    "\n",
    "        stft = tf.signal.stft(signal,\n",
    "                            frame_length=n_fft,\n",
    "                            frame_step = hop_length)\n",
    "        stft_amp = tf.abs(stft)\n",
    "        stft_amp = tf.transpose(stft_amp,perm=[2,1,0])\n",
    "        out_stft.append(stft_amp)\n",
    "    batched = tf.data.Dataset.from_tensor_slices(out_stft).batch(16)\n",
    "    fichier = open(filepath[:-4] + '.txt')\n",
    "    prediction = []\n",
    "    for line in fichier:\n",
    "        prediction.append(line.rstrip('\\n').rstrip('\\t'))\n",
    "    return batched,prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
